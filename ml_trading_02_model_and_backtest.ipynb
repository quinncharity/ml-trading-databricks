{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f1e3445-693a-4cdd-8bef-be9289e34d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d568d0f3-5cfb-44d0-ad08-1b1eed621033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# High-level experiment parameters\n",
    "cutoff_date = \"2020-01-01\"   # train/test split date\n",
    "long_threshold = 0.55        # P(up) threshold for long\n",
    "short_threshold = 0.45       # P(up) threshold for short\n",
    "\n",
    "feature_cols = [\"sma_20\", \"std_20\", \"daily_return\"]\n",
    "\n",
    "# Load labeled features created in Notebook 1\n",
    "df = spark.table(\"market.features_labeled\")\n",
    "\n",
    "# Drop rows with missing features/labels\n",
    "df_clean = df.dropna(subset=feature_cols + [\"label\"])\n",
    "\n",
    "display(\n",
    "    df_clean.select(\n",
    "        \"Date\", \"symbol\", \"Close\", \"sma_20\", \"std_20\", \"daily_return\", \"label\"\n",
    "    ).limit(10)\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "train = df_clean.filter(F.col(\"Date\") < cutoff_date)\n",
    "test = df_clean.filter(F.col(\"Date\") >= cutoff_date)\n",
    "\n",
    "print(f\"Train rows: {train.count():,}\")\n",
    "print(f\"Test rows:  {test.count():,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1421311-aaaa-4420-8612-f31cc1af058c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_sharpe(pdf: pd.DataFrame, ret_col: str = \"portfolio_return\") -> float | None:\n",
    "    \"\"\"\n",
    "    Compute annualized Sharpe ratio from a pandas DataFrame with a return column.\n",
    "    Assumes daily returns.\n",
    "    \"\"\"\n",
    "    mean_ret = pdf[ret_col].mean()\n",
    "    std_ret = pdf[ret_col].std()\n",
    "\n",
    "    if std_ret and std_ret != 0:\n",
    "        return (mean_ret / std_ret) * (252 ** 0.5)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df72729-d52b-4b50-bcdf-7afa40a1be05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Logistic regression model\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    regParam=0.0,\n",
    "    elasticNetParam=0.0,\n",
    "    maxIter=50\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "dataset = assembler.transform(df_clean)\n",
    "\n",
    "train = dataset.filter(F.col(\"Date\") < cutoff_date)\n",
    "test = dataset.filter(F.col(\"Date\") >= cutoff_date)\n",
    "\n",
    "model = lr.fit(train)\n",
    "\n",
    "# Predictions on test set\n",
    "preds = model.transform(test)\n",
    "\n",
    "preds_sel = preds.select(\n",
    "    \"Date\",\n",
    "    \"symbol\",\n",
    "    \"label\",\n",
    "    \"prediction\",\n",
    "    \"probability\",\n",
    "    \"daily_return\"\n",
    ")\n",
    "\n",
    "display(preds_sel.limit(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8189050e-0bdc-4be0-bf78-00eb9e06d33d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build trading strategy based on predicted probability of \"up\" (class 1)\n",
    "strategy_df = (\n",
    "    preds_sel\n",
    "    # convert vector -> array so we can index it\n",
    "    .withColumn(\"prob_array\", vector_to_array(\"probability\"))\n",
    "    .withColumn(\"p_up\", F.col(\"prob_array\")[1])  # P(class = 1)\n",
    "    .withColumn(\n",
    "        \"position\",\n",
    "        F.when(F.col(\"p_up\") > long_threshold, 1)\n",
    "         .when(F.col(\"p_up\") < short_threshold, -1)\n",
    "         .otherwise(0)\n",
    "    )\n",
    "    .withColumn(\"strategy_return\", F.col(\"position\") * F.col(\"daily_return\"))\n",
    ")\n",
    "\n",
    "display(strategy_df.limit(10))\n",
    "\n",
    "# Aggregate to daily portfolio returns\n",
    "portfolio_df = (\n",
    "    strategy_df\n",
    "    .groupBy(\"Date\")\n",
    "    .agg(\n",
    "        F.avg(\"strategy_return\").alias(\"portfolio_return\")\n",
    "    )\n",
    "    .orderBy(\"Date\")\n",
    ")\n",
    "\n",
    "# Build equal-weight buy-and-hold benchmark using daily_return\n",
    "benchmark_df = (\n",
    "    df_clean\n",
    "    .groupBy(\"Date\")\n",
    "    .agg(F.avg(\"daily_return\").alias(\"benchmark_return\"))\n",
    "    .orderBy(\"Date\")\n",
    ")\n",
    "\n",
    "# Combine strategy and benchmark, compute cumulative returns\n",
    "comparison_df = (\n",
    "    portfolio_df.alias(\"p\")\n",
    "    .join(benchmark_df.alias(\"b\"), \"Date\", \"inner\")\n",
    "    .select(\n",
    "        \"Date\",\n",
    "        \"portfolio_return\",\n",
    "        \"benchmark_return\",\n",
    "    )\n",
    ")\n",
    "\n",
    "w_date = Window.orderBy(\"Date\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "comparison_df = (\n",
    "    comparison_df\n",
    "    .withColumn(\"cml_return\", F.sum(\"portfolio_return\").over(w_date))\n",
    "    .withColumn(\"benchmark_cml_return\", F.sum(\"benchmark_return\").over(w_date))\n",
    ")\n",
    "\n",
    "pdf_compare = comparison_df.toPandas()\n",
    "\n",
    "# Compute Sharpe ratios\n",
    "ml_sharpe = compute_sharpe(pdf_compare, ret_col=\"portfolio_return\")\n",
    "benchmark_sharpe = compute_sharpe(pdf_compare, ret_col=\"benchmark_return\")\n",
    "\n",
    "print(\"Strategy Sharpe:\", ml_sharpe)\n",
    "print(\"Benchmark Sharpe:\", benchmark_sharpe)\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(pdf_compare[\"Date\"], pdf_compare[\"cml_return\"], label=\"ML strategy\")\n",
    "plt.plot(pdf_compare[\"Date\"], pdf_compare[\"benchmark_cml_return\"], label=\"Benchmark\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative returns: ML strategy vs. benchmark\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot rolling 3-month Sharpe for the strategy\n",
    "window = 63  # ~3 months of trading days\n",
    "pdf_compare[\"ml_rolling_sharpe\"] = (\n",
    "    pdf_compare[\"portfolio_return\"]\n",
    "    .rolling(window)\n",
    "    .apply(lambda x: compute_sharpe(pd.DataFrame({\"r\": x}), ret_col=\"r\") or 0.0)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(pdf_compare[\"Date\"], pdf_compare[\"ml_rolling_sharpe\"])\n",
    "plt.title(\"Rolling 3-month Sharpe (ML strategy)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ml_trading_02_model_and_backtest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
